# 数据定义语句

## 数据库

### 新建数据库

```sql
0: jdbc:hive2://node01:10000> create database if not exists mydb location '/user/hivedb';
No rows affected (1.642 seconds)
0: jdbc:hive2://node01:10000> show databases;
+----------------+--+
| database_name  |
+----------------+--+
| default        |
| mydb           |
+----------------+--+

0: jdbc:hive2://node01:10000> show databases like '*db*'; # 模糊查询数据库
+----------------+--+
| database_name  |
+----------------+--+
| mydb           |
+----------------+--+

0: jdbc:hive2://node01:10000> desc database mydb; # 查询数据库的描述信息
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| db_name  | comment  |           location            | owner_name  | owner_type  | parameters  |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| mydb     |          | hdfs://hacluster/user/hivedb  | root        | USER        |             |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+

0: jdbc:hive2://node01:10000> desc database extended mydb; #查看数据库的扩展信息
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| db_name  | comment  |           location            | owner_name  | owner_type  | parameters  |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| mydb     |          | hdfs://hacluster/user/hivedb  | root        | USER        |             |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
```

### 修改数据库

使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置

```sql
0: jdbc:hive2://node01:10000> alter database mydb set dbproperties('createtime'='20210127');
No rows affected (0.394 seconds)
0: jdbc:hive2://node01:10000> desc database extended mydb;
+----------+----------+-------------------------------+-------------+-------------+------------------------+--+
| db_name  | comment  |           location            | owner_name  | owner_type  |       parameters       |
+----------+----------+-------------------------------+-------------+-------------+------------------------+--+
| mydb     |          | hdfs://hacluster/user/hivedb  | root        | USER        | {createtime=20210127}  |
+----------+----------+-------------------------------+-------------+-------------+------------------------+--+
1 row selected (2.197 seconds)
```

### 删除数据库

如果数据库不为空，可以采用cascade命令，强制删除

```sql
0: jdbc:hive2://node01:10000> drop database mydb cascade;
No rows affected (4.809 seconds)
0: jdbc:hive2://node01:10000> show databases;
+----------------+--+
| database_name  |
+----------------+--+
| default        |
+----------------+--+
1 row selected (0.171 seconds)
```

## 表

### 建表

```sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)] 
[COMMENT table_comment] 
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 
[CLUSTERED BY (col_name, col_name, ...) 
[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] 
[ROW FORMAT row_format] 
[STORED AS file_format] 
[LOCATION hdfs_path]
```

**字段解释说明**

（1）**CREATE TABLE** 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。

（2）**EXTERNAL**关键字可以让用户创建一个外部表，在建表的同时指向实际数据的路径（LOCATION），Hive创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。

（3）**COMMENT** 为表和列添加注释。

（4）**PARTITIONED BY** 创建分区表

（5）**CLUSTERED BY** 创建分桶表

（6）**SORTED BY** 不常用

（7）ROW FORMAT 

DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]

​    [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] 

  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]

用户在建表的时候可以自定义SerDe或者使用自带的SerDe。如果没有指定ROW FORMAT 或者ROW FORMAT DELIMITED，将会使用自带的SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的SerDe，Hive通过SerDe确定表的具体的列的数据。

SerDe是Serialize/Deserilize的简称，目的是用于序列化和反序列化。

（8）**STORED AS** 指定存储文件类型

常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）

如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。

（9）**LOCATION**  指定表在HDFS上的存储位置。

（10）**LIKE** 允许用户复制现有的表结构，但是不复制数据。

**数据文件准备**

```sql
[root@node02 ~]# vi dept.txt
10	ACCOUNTING	1700
20	RESEARCH	1800
30	SALES	1900
40	OPERATIONS	1700

[root@node02 ~]# vi emp.txt
7369	SMITH	CLERK	7902	1980-12-17	800.00		20
7499	ALLEN	SALESMAN	7698	1981-2-20	1600.00	300.00	30
7521	WARD	SALESMAN	7698	1981-2-22	1250.00	500.00	30
7566	JONES	MANAGER	7839	1981-4-2	2975.00		20
7654	MARTIN	SALESMAN	7698	1981-9-28	1250.00	1400.00	30
7698	BLAKE	MANAGER	7839	1981-5-1	2850.00		30
7782	CLARK	MANAGER	7839	1981-6-9	2450.00		10
7788	SCOTT	ANALYST	7566	1987-4-19	3000.00		20
7839	KING	PRESIDENT		1981-11-17	5000.00		10
7844	TURNER	SALESMAN	7698	1981-9-8	1500.00	0.00	30
7876	ADAMS	CLERK	7788	1987-5-23	1100.00		20
7900	JAMES	CLERK	7698	1981-12-3	950.00		30
7902	FORD	ANALYST	7566	1981-12-3	3000.00		20
7934	MILLER	CLERK	7782	1982-1-23	1300.00		10
```

### 内部表和外部表

在删除表的时候，**内部表的元数据和数据会被一起删除**，而外部表只删除元数据，不删除数据。

```sql
# 创建部门表
create external table if not exists dept(
    deptno  int
   ,dname   string
   ,loc     int
)row format delimited fields terminated by '\t';
```

#### 查看表结构

```sql
0: jdbc:hive2://node01:10000> desc formatted dept;
+-------------------------------+-------------------------------------------------------------+-----------------------+--+
|           col_name            |                          data_type                          |        comment        |
+-------------------------------+-------------------------------------------------------------+-----------------------+--+
| # col_name                    | data_type                                                   | comment               |
|                               | NULL                                                        | NULL                  |
| deptno                        | int                                                         |                       |
| dname                         | string                                                      |                       |
| loc                           | int                                                         |                       |
|                               | NULL                                                        | NULL                  |
| # Detailed Table Information  | NULL                                                        | NULL                  |
| Database:                     | default                                                     | NULL                  |
| Owner:                        | root                                                        | NULL                  |
| CreateTime:                   | Sat Jan 30 04:42:55 CST 2021                                | NULL                  |
| LastAccessTime:               | UNKNOWN                                                     | NULL                  |
| Protect Mode:                 | None                                                        | NULL                  |
| Retention:                    | 0                                                           | NULL                  |
| Location:                     | hdfs://hacluster/user/hivedb/warehouse/dept                 | NULL                  |
| Table Type:                   | EXTERNAL_TABLE                                              | NULL                  |
| Table Parameters:             | NULL                                                        | NULL                  |
|                               | EXTERNAL                                                    | TRUE                  |
|                               | transient_lastDdlTime                                       | 1611952975            |
|                               | NULL                                                        | NULL                  |
| # Storage Information         | NULL                                                        | NULL                  |
| SerDe Library:                | org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe          | NULL                  |
| InputFormat:                  | org.apache.hadoop.mapred.TextInputFormat                    | NULL                  |
| OutputFormat:                 | org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat  | NULL                  |
| Compressed:                   | No                                                          | NULL                  |
| Num Buckets:                  | -1                                                          | NULL                  |
| Bucket Columns:               | []                                                          | NULL                  |
| Sort Columns:                 | []                                                          | NULL                  |
| Storage Desc Params:          | NULL                                                        | NULL                  |
|                               | field.delim                                                 | \t                    |
|                               | serialization.format                                        | \t                    |
+-------------------------------+-------------------------------------------------------------+-----------------------+--+
```

#### 内外部表相互转换

外转内

```sql
alter table dept set tblproperties('EXTERNAL'='FALSE');
| Table Type:                   | MANAGED_TABLE      # 内部表
```

内转外

```sql
alter table dept set tblproperties('EXTERNAL'='TRUE');
| Table Type:                   | EXTERNAL_TABLE     # 外部表      
```

注意：('EXTERNAL'='TRUE')和('EXTERNAL'='FALSE')为固定写法，区分大小写

### 分区表

Hive 中的分区就是分目录，在WHERE条件里用分区字段筛选，可以提高查询效率。 注意分区字段不能和表里已有的字段一样，不然会报错 Column repeated in partitioning columns。

#### 建分区表

```sql
# 按 pt_d 为分区字段创建员工表, 分区字段任意
create external table if not exists emp(
    empno       int
   ,ename       string
   ,job         string
   ,mgr         int
   ,hiredate    string
   ,sal         double
   ,comm        double
   ,deptno      int
)
partitioned by (pt_d int)
row format delimited fields terminated by '\t';
```

#### 添加分区

```sql
alter table emp add partition(pt_d='20210129');
```

![](./doc/05.png)

同时给表添加多个分区

```sql
alter table emp add partition(pt_d='20210127') partition(pt_d='20210128');
```

#### 删除分区

```sql
alter table emp drop partition(pt_d='20210129');
```

删除多个分区

```sql
alter table emp drop partition(pt_d='20210127'),partition(pt_d='20210128');
```

#### 查看分区

```sql
show partitions emp;
```

#### 多级分区

```sql
create external table if not exists ods_emp(
   empno       int
   ,ename       string
   ,job         string
   ,mgr         int
   ,hiredate    string
   ,sal         double
   ,comm        double
   ,deptno      int
)
partitioned by (pt_m String, pt_d String)
row format delimited fields terminated by '\t';
```

#### 修复分区

```sql
msck repair table emp;
```

### 分桶表



